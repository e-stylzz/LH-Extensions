extMain$EndDate <- as.Date(extMain$EndDate, format = "%m/%d/%Y")
extMain$ExtStartDate <- as.Date(extMain$ExtStartDate, format = "%m/%d/%Y")
extMain$ExtEndDate <- as.Date(extMain$ExtEndDate, format = "%m/%d/%Y")
#Convert to character, group subcontractor gypes into Subcontractor, then convert back to factor
extMain$PersonVitalizedEmployeeType <- as.character(extMain$PersonVitalizedEmployeeType)
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Partner Sourced"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Corporate"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Independent/1099"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: GLS"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType <- as.factor(extMain$PersonVitalizedEmployeeType)
#Define breaks for rates, then cut em up and throw them in a new field called RateGroups
breaks <- c(50, 100, 125, 130, 135, 140, 145, 150, 175, 200)
RateGroups <- cut(extMain$Rate, breaks= breaks)
summary(RateGroups)
extMain$RateGroup <- RateGroups
vars <- colnames(extMain)
catVars <- vars[sapply(extMain[,vars],class) %in% c('factor','character')]
numericVars <- vars[sapply(extMain[,vars],class) %in% c('numeric','integer')]
outcome <- 'Extended'
pos <- '1'
#Create Group for splitting data and break it up into Train & Test
extMain$Group <- runif(dim(extMain) [1])
test <- subset(extMain, extMain$Group <= 0.3)
train <- subset(extMain, extMain$Group > 0.3)
mkPredC <- function(outCol,varCol,appCol) {
pPos <- sum(outCol==pos)/length(outCol)
naTab <- table(as.factor(outCol[is.na(varCol)]))
pPosWna <- (naTab/sum(naTab))[pos]
vTab <-table(as.factor(outCol),varCol)
pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
pred <- pPosWv[appCol]
pred[is.na(appCol)] <- pPosWna
pred[is.na(pred)] <- pPos
pred
}
for(v in catVars) {
pi <- paste('pred',v,sep='')
train[,pi] <- mkPredC(train[,outcome],train[,v],train[,v])
test[,pi] <- mkPredC(train[,outcome],train[,v],test[,v])
}
calcAUC <- function(predcol,outcol) {
perf <- performance(prediction(predcol,outcol==pos),'auc')
as.numeric(perf@y.values)
}
for(v in catVars) {
pi <- paste('pred',v,sep='')
aucTrain <- calcAUC(train[,pi],train[,outcome])
if(aucTrain>=0.8) {
aucCal <- calcAUC(train[,pi],train[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
}
setwd("~/GitHub/LH-Extensions")
#Load CSV
extMain <- read.csv("~/GitHub/LH-Extensions/src/extmain.csv")
#Load Libraries
library('rpart')
library('rattle')
library('rpart.plot')
library('RColorBrewer')
library('randomForest')
library('party')
library('ggplot2')
library('lubridate')
library('ROCR')
#Convert to factor
extMain$Extended <- as.factor(extMain$Extended)
#Convert to dates
extMain$StartDate <- as.Date(extMain$StartDate, format = "%m/%d/%Y")
extMain$EndDate <- as.Date(extMain$EndDate, format = "%m/%d/%Y")
extMain$ExtStartDate <- as.Date(extMain$ExtStartDate, format = "%m/%d/%Y")
extMain$ExtEndDate <- as.Date(extMain$ExtEndDate, format = "%m/%d/%Y")
#Convert to character, group subcontractor gypes into Subcontractor, then convert back to factor
extMain$PersonVitalizedEmployeeType <- as.character(extMain$PersonVitalizedEmployeeType)
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Partner Sourced"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Corporate"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Independent/1099"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: GLS"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType <- as.factor(extMain$PersonVitalizedEmployeeType)
#Define breaks for rates, then cut em up and throw them in a new field called RateGroups
breaks <- c(50, 100, 125, 130, 135, 140, 145, 150, 175, 200)
RateGroups <- cut(extMain$Rate, breaks= breaks)
summary(RateGroups)
extMain$RateGroup <- RateGroups
vars <- colnames(extMain)
catVars <- vars[sapply(extMain[,vars],class) %in% c('factor','character')]
numericVars <- vars[sapply(extMain[,vars],class) %in% c('numeric','integer')]
outcome <- 'Extended'
pos <- '1'
#Create Group for splitting data and break it up into Train & Test
extMain$Group <- runif(dim(extMain) [1])
test <- subset(extMain, extMain$Group <= 0.3)
trainall <- subset(extMain, extMain$Group > 0.3)
useForCal <- rbinom(n=dim(trainall) [[1]],size=1,prob=0.1)>0
cal <- subset(trainall,useForCal)
train <- subset(trainall, !useForCal)
mkPredC <- function(outCol,varCol,appCol) {
pPos <- sum(outCol==pos)/length(outCol)
naTab <- table(as.factor(outCol[is.na(varCol)]))
pPosWna <- (naTab/sum(naTab))[pos]
vTab <-table(as.factor(outCol),varCol)
pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
pred <- pPosWv[appCol]
pred[is.na(appCol)] <- pPosWna
pred[is.na(pred)] <- pPos
pred
}
for(v in catVars) {
pi <- paste('pred',v,sep='')
train[,pi] <- mkPredC(train[,outcome],train[,v],train[,v])
cal[,pi] <- mkPredC(train[,outcome],train[,v],cal[,v])
test[,pi] <- mkPredC(train[,outcome],train[,v],test[,v])
}
calcAUC <- function(predcol,outcol) {
perf <- performance(prediction(predcol,outcol==pos),'auc')
as.numeric(perf@y.values)
}
for(v in catVars) {
pi <- paste('pred',v,sep='')
aucTrain <- calcAUC(train[,pi],train[,outcome])
if(aucTrain>=0.8) {
aucCal <- calcAUC(cal[,pi],cal[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
}
mkPredN <- function(outCol,varCol,appCol) {
cuts <- unique(as.numeric(quantile(varCol,probs=seq(0, 1, 0.1),na.rm=T)))
varC <- cut(varCol,cuts)
appC <- cut(appCol,cuts)
mkPredC(outCol,varC,appC)
}
for(v in numericVars) {
pi <- paste('pred',v,sep='')
train[,pi] <- mkPredN(train[,outcome],train[,v],train[,v])
test[,pi] <- mkPredN(train[,outcome],train[,v],test[,v])
cal[,pi] <- mkPredN(train[,outcome],train[,v],cal[,v])
aucTrain <- calcAUC(train[,pi],train[,outcome])
if(aucTrain>=.55) {
aucCal <- calcAUC(cal[,pi],cal[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
}
logLikelyhood <- function(outCol,predCol) {
sum(ifelse(outCol==pos,log(predCol),log(1-predCol)))
}
entropy <- function(x) {
xpos <- x[x>0 & !is.na(x)]
scaled <- xpos/sum(xpos)
sum(-scaled*log(scaled,2))
}
nPos <- sum(train[,outcome]==pos)
pPos <- nPos/length(train[,outcome])
eps <- 1.0e-5
for(v in c(catVars,numericVars)) {
pi <- paste('pred',v,sep='')
li <- paste('lift',v,sep='')
train[,li] <- log((train[,pi]+eps)/(pPos+eps))
test[,li] <- log((test[,pi]+eps)/(pPos+eps))
cal[,li] <- log((cal[,pi]+eps)/(pPos+eps))
}
selVars <- c()
minStep <- 5
baseRateTrain <- logLikelyhood(train[,outcome],sum(train[,outcome]==pos)/length(train[,outcome]))
baseRateCheck <- logLikelyhood(cal[,outcome],sum(cal[,outcome]==pos)/length(cal[,outcome]))
for(v in catVars) {
pi <- paste('pred',v,sep='')
li <- paste('lift',v,sep='')
liTrain <- 2*(logLikelyhood(train[,outcome],train[,pi])- baseRateTrain - 2^entropy(table(train[,pi],useNA='ifany')))
liCheck <- 2*(logLikelyhood(train[,outcome],train[,pi]) - baseRateCheck - 2^entropy(table(train[,pi],useNA='ifany')))
if((liTrain>=minStep)&(liCheck>minStep)) {
print(sprintf("%s, trainAIC: %g calibrationAIC: %g",
pi,liTrain,liCheck))
selVars <- c(selVars,li)
}
}
print(selVars)
for(v in numericVars) {
pi <- paste('pred',v,sep='')
li <- paste('lift',v,sep='')
liTrain <- 2*(logLikelyhood(train[,outcome],train[,pi])-baseRateTrain-1)
liCheck <- 2*(logLikelyhood(train[,outcome],train[,pi])-baseRateCheck-1)
if((liTrain>=minStep) && (liCheck>=minStep)) {
print(sprintf("%s, trainAIC: %g calibrationAIC: %g",
pi,liTrain,liCheck))
selVars <- c(selVars,li)
}
}
print(selVars)
f <- paste(outcome,'>0 ~ ',paste(selVars,collapse=' + '),sep='')
model <- glm(as.formula(f),data=train,family=binomial(link='logit'))
f <- paste(outcome,' ~ ',paste(selVars,collapse=' + '),sep='')
model <- glm(as.formula(f),data=train,family=binomial(link='logit'))
print(summary(model))
train$pred <- predict(model,type='response',newdata=train)
cal$pred <- predict(model,type='response',newdata=cal)
test$pred <- predict(model,type='response',newdata=test)
summary(numericVars)
setwd("~/GitHub/LH-Extensions")
#Load CSV
#extMain <- read.csv("~/GitHub/LH-Extensions/src/extmain.csv")
extMain <- read.csv("~/GitHub/LH-Extensions/src/extmain_u.csv")
#Load Libraries
library('rpart')
library('rattle')
library('rpart.plot')
library('RColorBrewer')
library('randomForest')
library('party')
library('ggplot2')
library('lubridate')
library('ROCR')
#Convert to dates
extMain$StartDate <- as.Date(extMain$StartDate, format = "%m/%d/%Y")
extMain$EndDate <- as.Date(extMain$EndDate, format = "%m/%d/%Y")
#extMain$ExtStartDate <- as.Date(extMain$ExtStartDate, format = "%m/%d/%Y")
#extMain$ExtEndDate <- as.Date(extMain$ExtEndDate, format = "%m/%d/%Y")
#Convert to character, group subcontractor gypes into Subcontractor, then convert back to factor
extMain$PersonVitalizedEmployeeType <- as.character(extMain$PersonVitalizedEmployeeType)
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Partner Sourced"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Corporate"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Independent/1099"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: GLS"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType <- as.factor(extMain$PersonVitalizedEmployeeType)
#Define breaks for rates, then cut em up and throw them in a new field called RateGroups
breaks <- c(50, 100, 125, 130, 135, 140, 145, 150, 175, 200)
RateGroups <- cut(extMain$Rate, breaks= breaks)
summary(RateGroups)
extMain$RateGroup <- RateGroups
####New Stuff to test and compare :  Cound variables include in these sets before and after load
####outcomes=c('Extended')
#vars <- setdiff(colnames(train), c(outcomes,'rgroup'))
vars <- colnames(extMain)
catVars <- vars[sapply(extMain[,vars],class) %in% c('factor','character')]
numericVars <- vars[sapply(extMain[,vars],class) %in% c('numeric','integer')]
outcome <- 'Extended'
pos <- '1'
#Create Group for splitting data and break it up into Train & Test
extMain$Group <- runif(dim(extMain) [1])
test <- subset(extMain, extMain$Group <= 0.3)
trainall <- subset(extMain, extMain$Group > 0.3)
#Split Training Data into a Training and Calibration Set
useForCal <- rbinom(n=dim(trainall) [[1]],size=1,prob=0.1)>0
cal <- subset(trainall,useForCal)
train <- subset(trainall, !useForCal)
#Function to make predictions on Cat Values
mkPredC <- function(outCol,varCol,appCol) {
pPos <- sum(outCol==pos)/length(outCol)
naTab <- table(as.factor(outCol[is.na(varCol)]))
pPosWna <- (naTab/sum(naTab))[pos]
vTab <-table(as.factor(outCol),varCol)
pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
pred <- pPosWv[appCol]
pred[is.na(appCol)] <- pPosWna
pred[is.na(pred)] <- pPos
pred
}
#Here i believe we start to loop through catVariables and build our prediction code to pass into the Prediction Function for catVars
for(v in catVars) {
pi <- paste('pred',v,sep='')
train[,pi] <- mkPredC(train[,outcome],train[,v],train[,v])
cal[,pi] <- mkPredC(train[,outcome],train[,v],cal[,v])
test[,pi] <- mkPredC(train[,outcome],train[,v],test[,v])
}
#Building the function to calculate AUC
calcAUC <- function(predcol,outcol) {
perf <- performance(prediction(predcol,outcol==pos),'auc')
as.numeric(perf@y.values)
}
#Code to loop through catVars and push prediction statements per row into the calcAUC function.  This returns a percent, that if higher then
#0.8 we print out the info to screen:  Variable Name, TrainAUC, and calibrationAUC.  Right before asigning the calibration numbers it throws
#number to the same calcAUC function based on the calibration set and thats whats printed with calibrationAUC.
#It seems to be better to use variables with a higher number for calibrationAUC as it better adjsuts for variables with many levels.
for(v in catVars) {
pi <- paste('pred',v,sep='')
aucTrain <- calcAUC(train[,pi],train[,outcome])
if(aucTrain>=0.8) {
aucCal <- calcAUC(cal[,pi],cal[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
}
#This function is is designed to be fed with variables/info from numericaVars.  Its going to cut them up into categories as pass to the
#makePredC function
mkPredN <- function(outCol,varCol,appCol) {
cuts <- unique(as.numeric(quantile(varCol,probs=seq(0, 1, 0.1),na.rm=T)))
varC <- cut(varCol,cuts)
appC <- cut(appCol,cuts)
mkPredC(outCol,varC,appC)
}
#Much like the for loop above for catVars, this loops through the numerica vars preparing the data and passing it into the mkPredN function above
for(v in numericVars) {
pi <- paste('pred',v,sep='')
train[,pi] <- mkPredN(train[,outcome],train[,v],train[,v])
test[,pi] <- mkPredN(train[,outcome],train[,v],test[,v])
cal[,pi] <- mkPredN(train[,outcome],train[,v],cal[,v])
aucTrain <- calcAUC(train[,pi],train[,outcome])
if(aucTrain>=.55) {
aucCal <- calcAUC(cal[,pi],cal[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
}
logLikelyhood <- function(outCol,predCol) {
sum(ifelse(outCol==pos,log(predCol),log(1-predCol)))
}
entropy <- function(x) {
xpos <- x[x>0 & !is.na(x)]
scaled <- xpos/sum(xpos)
sum(-scaled*log(scaled,2))
}
nPos <- sum(train[,outcome]==pos)
pPos <- nPos/length(train[,outcome])
eps <- 1.0e-5
for(v in c(catVars,numericVars)) {
pi <- paste('pred',v,sep='')
li <- paste('lift',v,sep='')
train[,li] <- log((train[,pi]+eps)/(pPos+eps))
test[,li] <- log((test[,pi]+eps)/(pPos+eps))
cal[,li] <- log((cal[,pi]+eps)/(pPos+eps))
}
selVars <- c()
minStep <- 5
baseRateTrain <- logLikelyhood(train[,outcome],sum(train[,outcome]==pos)/length(train[,outcome]))
baseRateCheck <- logLikelyhood(cal[,outcome],sum(cal[,outcome]==pos)/length(cal[,outcome]))
for(v in catVars) {
pi <- paste('pred',v,sep='')
li <- paste('lift',v,sep='')
liTrain <- 2*(logLikelyhood(train[,outcome],train[,pi])- baseRateTrain - 2^entropy(table(train[,pi],useNA='ifany')))
liCheck <- 2*(logLikelyhood(train[,outcome],train[,pi]) - baseRateCheck - 2^entropy(table(train[,pi],useNA='ifany')))
if((liTrain>=minStep)&(liCheck>minStep)) {
print(sprintf("%s, trainAIC: %g calibrationAIC: %g",
pi,liTrain,liCheck))
selVars <- c(selVars,li)
}
}
print(selVars)
for(v in numericVars) {
pi <- paste('pred',v,sep='')
li <- paste('lift',v,sep='')
liTrain <- 2*(logLikelyhood(train[,outcome],train[,pi])-baseRateTrain-1)
liCheck <- 2*(logLikelyhood(train[,outcome],train[,pi])-baseRateCheck-1)
if((liTrain>=minStep) && (liCheck>=minStep)) {
print(sprintf("%s, trainAIC: %g calibrationAIC: %g",
pi,liTrain,liCheck))
selVars <- c(selVars,li)
}
}
print(selVars)
f-orig <- paste(outcome,'>0 ~ ',paste(selVars,collapse=' + '),sep='')
forig <- paste(outcome,'>0 ~ ',paste(selVars,collapse=' + '),sep='')
f <- paste(outcome,' ~ ',paste(selVars,collapse=' + '),sep='')
modelorig <- glm(as.formula(forig),data=train,family=binomial(link='logit'))
modelorig <- glm(as.formula(forig),data=train,family=binomial(link='logit'))
model <- glm(as.formula(f),data=train,family=binomial(link='logit'))
f <- paste(outcome,' ~ ',paste(v,collapse=' + '),sep='')
model <- glm(as.formula(f),data=train,family=binomial(link='logit'))
train$pred <- predict(model,type='response',newdata=train)
cal$pred <- predict(model,type='response',newdata=cal)
test$pred <- predict(model,type='response',newdata=test)
perfTrain <- performance(prediction(train$pred,train[,outcome]>0),'auc')
perfCal <- performance(prediction(dCal$pred,dCal[,outcome]>0),'auc')
perfTest <- performance(prediction(test$pred,test[,outcome]>0),'auc')
print(paste('train',as.numeric(perfTrain@y.values)))
print(paste('cal',as.numeric(perfCal@y.values)))
print(paste('test',as.numeric(perfTest@y.values)))
perfTrain <- performance(prediction(train$pred,train[,outcome]>0),'auc')
perfCal <- performance(prediction(Cal$pred,cal[,outcome]>0),'auc')
perfTest <- performance(prediction(test$pred,test[,outcome]>0),'auc')
print(paste('train',as.numeric(perfTrain@y.values)))
print(paste('cal',as.numeric(perfCal@y.values)))
print(paste('test',as.numeric(perfTest@y.values)))
perfTrain <- performance(prediction(train$pred,train[,outcome]>0),'auc')
perfCal <- performance(prediction(cal$pred,cal[,outcome]>0),'auc')
perfTest <- performance(prediction(test$pred,test[,outcome]>0),'auc')
print(paste('train',as.numeric(perfTrain@y.values)))
print(paste('cal',as.numeric(perfCal@y.values)))
print(paste('test',as.numeric(perfTest@y.values)))
modelRateTrain <- logLikelyhood(train[,outcome],train$pred)
modelRateCal <- logLikelyhood(cal[,outcome],cal$pred)
modelRateTest <- logLikelyhood(test[,outcome],test$pred)
ggplot(train) + geom_bar(aes(x= EngDuration, fill= Extended),position = "dodge")
ggplot(train) + geom_bar(aes(x= EngDuration, fill= Extended),position = "fill")
model2 <- glm(train$Extended ~ train$EngDuration + train$Rate, data=train, family=binomial(link="logit"))
model2 <- glm(train$Extended ~ train$EngDuration + train$Rate, data=train, family=binomial(link="logit"))
train$extPred <- predict(model2, newdata=train, type="response")
ggplot(train, aes(x=extPred, color=Extended, linetype=Extended)) +
geom_density()
summary(tain)
summary(train)
str(train)
ggplot(train, aes(x=extPred, color=Extended, linetype=Extended)) +
geom_density()
train$extPred <- as.factor(train$extPred)
ggplot(train, aes(x=extPred, color=Extended, linetype=Extended)) +
geom_density()
train$extPred <- as.number(train$extPred)
train$extPred <- as.numeric(train$extPred)
confusion <- table(pred=train$extPred>0.5, Extended=train$Extended)
confusion
confusion <- table(pred=train$extPred>0.7, Extended=train$Extended)
confusion
confusion <- table(pred=train$extPred>0.9, Extended=train$Extended)
confusion
View(train)
confusion <- table(pred=train$pred>0.9, Extended=train$Extended)
confusion
confusion <- table(pred=train$pred>0.5, Extended=train$Extended)
confusion
ggplot(train, aes(x=pred, color=Extended, linetype=Extended)) +
geom_density()
precision <- confusion[2,2]/sum(confusion[2,])
precision
recall <- confusion[2,2]/sum(confusion[,2])
recall
enrich <- precision/mean(as.numeric(train$Extended))
enrich
acuracy <- sum(diag(confusion)/sum(confusion))
acuracy
f <- paste(outcome,' ~ ',paste(numericVars,collapse=' + '),sep='')
model <- glm(as.formula(f),data=train,family=binomial(link='logit'))
f <- paste(outcome,' ~ ',paste(v,collapse=' + '),sep='')
model <- glm(as.formula(f),data=train,family=binomial(link='logit'))
setwd("~/GitHub/LH-Extensions")
#Load CSV
#extMain <- read.csv("~/GitHub/LH-Extensions/src/extmain.csv")
extMain <- read.csv("~/GitHub/LH-Extensions/src/extmain_u.csv")
#Load Libraries
library('rpart')
library('rattle')
library('rpart.plot')
library('RColorBrewer')
library('randomForest')
library('party')
library('ggplot2')
library('lubridate')
library('ROCR')
#Convert to factor
extMain$Extended <- as.factor(extMain$Extended)
#Convert to dates
extMain$StartDate <- as.Date(extMain$StartDate, format = "%m/%d/%Y")
extMain$EndDate <- as.Date(extMain$EndDate, format = "%m/%d/%Y")
#extMain$ExtStartDate <- as.Date(extMain$ExtStartDate, format = "%m/%d/%Y")
#extMain$ExtEndDate <- as.Date(extMain$ExtEndDate, format = "%m/%d/%Y")
#Convert to character, group subcontractor gypes into Subcontractor, then convert back to factor
extMain$PersonVitalizedEmployeeType <- as.character(extMain$PersonVitalizedEmployeeType)
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Partner Sourced"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Corporate"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: Independent/1099"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType[extMain$PersonVitalizedEmployeeType == "Subcontractor: GLS"] <- "Subcontractor"
extMain$PersonVitalizedEmployeeType <- as.factor(extMain$PersonVitalizedEmployeeType)
#Define breaks for rates, then cut em up and throw them in a new field called RateGroups
breaks <- c(50, 100, 125, 130, 135, 140, 145, 150, 175, 200)
RateGroups <- cut(extMain$Rate, breaks= breaks)
summary(RateGroups)
extMain$RateGroup <- RateGroups
####New Stuff to test and compare :  Cound variables include in these sets before and after load
####outcomes=c('Extended')
#vars <- setdiff(colnames(train), c(outcomes,'rgroup'))
vars <- colnames(extMain)
catVars <- vars[sapply(extMain[,vars],class) %in% c('factor','character')]
numericVars <- vars[sapply(extMain[,vars],class) %in% c('numeric','integer')]
outcome <- 'Extended'
pos <- '1'
#Create Group for splitting data and break it up into Train & Test
extMain$Group <- runif(dim(extMain) [1])
test <- subset(extMain, extMain$Group <= 0.3)
trainall <- subset(extMain, extMain$Group > 0.3)
#Split Training Data into a Training and Calibration Set
useForCal <- rbinom(n=dim(trainall) [[1]],size=1,prob=0.1)>0
cal <- subset(trainall,useForCal)
train <- subset(trainall, !useForCal)
str(train)
#Function to make predictions on Cat Values
mkPredC <- function(outCol,varCol,appCol) {
pPos <- sum(outCol==pos)/length(outCol)
naTab <- table(as.factor(outCol[is.na(varCol)]))
pPosWna <- (naTab/sum(naTab))[pos]
vTab <-table(as.factor(outCol),varCol)
pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
pred <- pPosWv[appCol]
pred[is.na(appCol)] <- pPosWna
pred[is.na(pred)] <- pPos
pred
}
#Here i believe we start to loop through catVariables and build our prediction code to pass into the Prediction Function for catVars
for(v in catVars) {
pi <- paste('pred',v,sep='')
train[,pi] <- mkPredC(train[,outcome],train[,v],train[,v])
cal[,pi] <- mkPredC(train[,outcome],train[,v],cal[,v])
test[,pi] <- mkPredC(train[,outcome],train[,v],test[,v])
}
#Building the function to calculate AUC
calcAUC <- function(predcol,outcol) {
perf <- performance(prediction(predcol,outcol==pos),'auc')
as.numeric(perf@y.values)
}
#Code to loop through catVars and push prediction statements per row into the calcAUC function.  This returns a percent, that if higher then
#0.8 we print out the info to screen:  Variable Name, TrainAUC, and calibrationAUC.  Right before asigning the calibration numbers it throws
#number to the same calcAUC function based on the calibration set and thats whats printed with calibrationAUC.
#It seems to be better to use variables with a higher number for calibrationAUC as it better adjsuts for variables with many levels.
for(v in catVars) {
pi <- paste('pred',v,sep='')
aucTrain <- calcAUC(train[,pi],train[,outcome])
if(aucTrain>=0.8) {
aucCal <- calcAUC(cal[,pi],cal[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
}
